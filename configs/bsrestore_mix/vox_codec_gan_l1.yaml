project_name: "bsrestore_mix"
exp_name: "vox_codec_gan_l1"

model:
  name: "BSRoFormer"
  params:
    dim: 256
    depth: 12
    stereo: true
    num_stems: 1
    time_transformer_depth: 1
    freq_transformer_depth: 1
    linear_transformer_depth: 0
    freqs_per_bands: !!python/tuple
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 4
      - 4
      - 4
      - 4
      - 4
      - 4
      - 4
      - 4
      - 4
      - 4
      - 4
      - 4
      - 12
      - 12
      - 12
      - 12
      - 12
      - 12
      - 12
      - 12
      - 24
      - 24
      - 24
      - 24
      - 24
      - 24
      - 24
      - 24
      - 48
      - 48
      - 48
      - 48
      - 48
      - 48
      - 48
      - 48
      - 128
      - 129
    dim_head: 64
    heads: 8
    attn_dropout: 0.1
    ff_dropout: 0.1
    flash_attn: true
    dim_freqs_in: 1025
    stft_n_fft: 2048
    stft_hop_length: 512
    stft_win_length: 2048
    stft_normalized: false
    mask_estimator_depth: 2
    multi_stft_resolution_loss_weight: 1.0
    multi_stft_resolutions_window_sizes: !!python/tuple
    - 4096
    - 2048
    - 1024
    - 512
    - 256
    multi_stft_hop_size: 147
    multi_stft_normalized: False
    mlp_expansion_factor: 4
    use_torch_checkpoint: False # it allows to greatly reduce GPU memory consumption during training (not fully tested)
    skip_connection: False # Enable skip connection between transformer blocks - can solve problem with gradients and probably faster training

discriminators:
  - name: "MultiFrequencyDiscriminator"
    params:
      nch: 1
      window_sizes: [2048, 1024, 512]
      sample_rate: 48000
      norm: True

data:
  sample_rate: 48000
  clip_duration: 10.0
  train_dataset:
    target_stem: "Voc"
    root_directory: "/inspire/hdd/project/multilingualspeechrecognition/chenxie-25019/data/RawStems"
    apply_augmentation: True
    snr_range: [0.0, 10.0]
    output_mixture: True
  train_dataset1:
    target_stem: "vox"
    root_directory: "/inspire/hdd/project/multilingualspeechrecognition/chenxie-25019/data/moisesdb_raw"
    apply_augmentation: True
    snr_range: [0.0, 10.0]
    output_mixture: True
    moisesdb: True
  val_dataset:
    target_stem: "Voc"
    root_directory: "/inspire/hdd/project/multilingualspeechrecognition/chenxie-25019/data/RawStems_valid"
    apply_augmentation: True
    snr_range: [0.0, 10.0]
    output_mixture: True
  dataloader_params:
    batch_size: 4
    num_workers: 32

optimizer_g:
  lr: 0.0002
  betas: [0.8, 0.99]

optimizer_d:
  lr: 0.0002
  betas: [0.8, 0.99]

scheduler:
  warm_up_steps: 10000

losses:
  gan_type: 'lsgan'
  lambda_recon: 100.0
  lambda_feat: 2.0
  lambda_gan: 1.0
  reconstruction_loss:
    sample_rate: 48000
    n_fft: [1024, 2048, 512]
    hop_length: [256, 512, 128]
    n_mels: [80, 160, 40]
  spec_ratio: 0.0

trainer:
  max_steps: 1000000
  log_every_n_steps: 100
  checkpoint_save_interval: 10000
  limit_train_batches: 2000
  devices: [0]
  precision: 16-mixed
  save_dir: logs/

checkpoint:
  path: "/inspire/hdd/project/multilingualspeechrecognition/chenxie-25019/jinxuanzhu/MSRKit/checkpoints/BS-Rofo-SW-Fixed.ckpt"
  type: "roformer"