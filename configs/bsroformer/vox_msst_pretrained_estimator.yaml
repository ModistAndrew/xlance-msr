project_name: "bsroformer"
exp_name: "vox_msst_pretrained_estimator_v1"

model:
  name: "BSRoFormer"
  params:
    dim: 256
    depth: 12
    stereo: true
    num_stems: 1
    time_transformer_depth: 1
    freq_transformer_depth: 1
    linear_transformer_depth: 0
    freqs_per_bands: !!python/tuple
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 2
      - 4
      - 4
      - 4
      - 4
      - 4
      - 4
      - 4
      - 4
      - 4
      - 4
      - 4
      - 4
      - 12
      - 12
      - 12
      - 12
      - 12
      - 12
      - 12
      - 12
      - 24
      - 24
      - 24
      - 24
      - 24
      - 24
      - 24
      - 24
      - 48
      - 48
      - 48
      - 48
      - 48
      - 48
      - 48
      - 48
      - 128
      - 129
    dim_head: 64
    heads: 8
    attn_dropout: 0.1
    ff_dropout: 0.1
    flash_attn: true
    dim_freqs_in: 1025
    stft_n_fft: 2048
    stft_hop_length: 512
    stft_win_length: 2048
    stft_normalized: false
    mask_estimator_depth: 2
    multi_stft_resolution_loss_weight: 1.0
    multi_stft_resolutions_window_sizes: !!python/tuple
    - 4096
    - 2048
    - 1024
    - 512
    - 256
    multi_stft_hop_size: 147
    multi_stft_normalized: False
    mlp_expansion_factor: 4
    use_torch_checkpoint: False # it allows to greatly reduce GPU memory consumption during training (not fully tested)
    skip_connection: False # Enable skip connection between transformer blocks - can solve problem with gradients and probably faster training

data:
  sample_rate: 44100
  clip_duration: 13.351473923
  train_dataset:
    target_stem: "Voc"
    root_directory: "/inspire/hdd/project/multilingualspeechrecognition/chenxie-25019/data/RawStems"
    apply_augmentation: False
    snr_range: [0.0, 10.0]
  val_dataset:
    target_stem: "Voc"
    root_directory: "/inspire/hdd/project/multilingualspeechrecognition/chenxie-25019/data/RawStems_valid"
    apply_augmentation: False
    snr_range: [0.0, 10.0]
  dataloader_params:
    batch_size: 4
    num_workers: 16

optimizer_g:
  lr: 0.00002
  betas: [0.8, 0.99]

scheduler:
  warm_up_steps: 10000

trainer:
  max_steps: 1000000
  log_every_n_steps: 100
  checkpoint_save_interval: 10000
  limit_train_batches: 2000
  devices: [0]
  precision: 16-mixed
  save_dir: logs/

checkpoint:
  path: "/inspire/hdd/project/multilingualspeechrecognition/chenxie-25019/jinxuanzhu/MSRKit/checkpoints/BS-Rofo-SW-Fixed.ckpt"
  type: "roformer_vocal"